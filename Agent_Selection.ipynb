{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import operator\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:15:00+00:00</td>\n",
       "      <td>fk91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, I have a minimal linux system: how can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:15:00+00:00</td>\n",
       "      <td>fk91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Maco: ip is there, thanks :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:15:00+00:00</td>\n",
       "      <td>sometux</td>\n",
       "      <td>fk91</td>\n",
       "      <td>ifconfig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:15:00+00:00</td>\n",
       "      <td>sometux</td>\n",
       "      <td>fk91</td>\n",
       "      <td>static or dhcp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:16:00+00:00</td>\n",
       "      <td>fk91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:16:00+00:00</td>\n",
       "      <td>sometux</td>\n",
       "      <td>fk91</td>\n",
       "      <td>look at /etc/interface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:17:00+00:00</td>\n",
       "      <td>fk91</td>\n",
       "      <td>sometux</td>\n",
       "      <td>/etc/interfaces are not there, its a fli4l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:17:00+00:00</td>\n",
       "      <td>sometux</td>\n",
       "      <td>fk91</td>\n",
       "      <td>sorry look at /etc/network/interfaces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:18:00+00:00</td>\n",
       "      <td>fk91</td>\n",
       "      <td>sometux</td>\n",
       "      <td>This file isnt there too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-10000</td>\n",
       "      <td>2010-04-17 20:19:00+00:00</td>\n",
       "      <td>sometux</td>\n",
       "      <td>fk91</td>\n",
       "      <td>i think you have to look in /proc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  conversation_id                   datetime     from       to  \\\n",
       "0        10-10000  2010-04-17 20:15:00+00:00     fk91      NaN   \n",
       "1        10-10000  2010-04-17 20:15:00+00:00     fk91      NaN   \n",
       "2        10-10000  2010-04-17 20:15:00+00:00  sometux     fk91   \n",
       "3        10-10000  2010-04-17 20:15:00+00:00  sometux     fk91   \n",
       "4        10-10000  2010-04-17 20:16:00+00:00     fk91      NaN   \n",
       "5        10-10000  2010-04-17 20:16:00+00:00  sometux     fk91   \n",
       "6        10-10000  2010-04-17 20:17:00+00:00     fk91  sometux   \n",
       "7        10-10000  2010-04-17 20:17:00+00:00  sometux     fk91   \n",
       "8        10-10000  2010-04-17 20:18:00+00:00     fk91  sometux   \n",
       "9        10-10000  2010-04-17 20:19:00+00:00  sometux     fk91   \n",
       "\n",
       "                                                text  \n",
       "0  Hello, I have a minimal linux system: how can ...  \n",
       "1                      @Maco: ip is there, thanks :)  \n",
       "2                                           ifconfig  \n",
       "3                                     static or dhcp  \n",
       "4                                             static  \n",
       "5                             look at /etc/interface  \n",
       "6         /etc/interfaces are not there, its a fli4l  \n",
       "7              sorry look at /etc/network/interfaces  \n",
       "8                          This file isnt there too.  \n",
       "9                  i think you have to look in /proc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data into as a pandas data frame\n",
    "data = pd.read_csv(\"./data/ubuntu_support_extract.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3075574 entries, 0 to 3075573\n",
      "Data columns (total 5 columns):\n",
      "conversation_id    object\n",
      "datetime           object\n",
      "from               object\n",
      "to                 object\n",
      "text               object\n",
      "dtypes: object(5)\n",
      "memory usage: 117.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id          0\n",
       "datetime                 0\n",
       "from                    25\n",
       "to                 1133776\n",
       "text                     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of rows with missing values in each of the columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075547, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing rows which with missing values in 'text' and 'from' columns only,\n",
    "# column 'to' can have valid null values in the first msg of the conversation.\n",
    "data = data.dropna(subset=['text','from']) \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversation_id          0\n",
       "datetime                 0\n",
       "from                     0\n",
       "to                 1133752\n",
       "text                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying if rows with null values in 'text' and 'from' columns are removed\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92495 , 89090\n"
     ]
    }
   ],
   "source": [
    "from_users = data['from'].tolist()\n",
    "to_users = data['to'].tolist()\n",
    "print(len(set(from_users)), ',', len(set(to_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92519\n"
     ]
    }
   ],
   "source": [
    "# Total number of unique users\n",
    "print(len(set(from_users + to_users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count based approach for selecting agents\n",
    "A naive count based selection of agents. Rationale is that the users involved in high number of messages/conversations are:\n",
    "1. either advisors who responded to an issue\n",
    "2. or enquirers who gained knowledge after querying about an issue\n",
    "\n",
    "Either way, users involved in both sides of conversation are assumed to have knowledge of the covered topics\n",
    "'after' a conversation has taken place.\n",
    "\n",
    "Minimal incremental improvements: \n",
    "1. Filter out users who were on the advising side most of the times, based on the initial inquiry in the conversation.\n",
    "2. Give more weightage to the users who are currently active, based on date time. \n",
    "3. Ranking agents based on the average handle/response time based on the time stamps. \n",
    "4. The below agent selection mechanism does not use the language used in the conversations to filter out the conversations in a different language. But this can be done in a minimal way by using off the shelf language detectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing total incoming and outgoing messages for each user. \n",
    "from_user_dist = data.drop(columns=['text','to','datetime']).groupby(['from'])\\\n",
    "                              .size().reset_index(name='outgoing')\n",
    "\n",
    "from_user_dist = from_user_dist.rename(columns={'from': 'users'})\n",
    "\n",
    "to_user_dist = data.drop(columns=['text','from','datetime']).groupby(['to'])\\\n",
    "                            .size().reset_index(name='incoming') \n",
    "to_user_dist = to_user_dist.rename(columns={'to': 'users'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>outgoing</th>\n",
       "      <th>incoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>ActionParsnip</td>\n",
       "      <td>55125</td>\n",
       "      <td>27053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>Dr_Willis</td>\n",
       "      <td>36626</td>\n",
       "      <td>16590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51341</th>\n",
       "      <td>ikonia</td>\n",
       "      <td>30715</td>\n",
       "      <td>13762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43183</th>\n",
       "      <td>edbian</td>\n",
       "      <td>21307</td>\n",
       "      <td>9511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54888</th>\n",
       "      <td>jrib</td>\n",
       "      <td>18491</td>\n",
       "      <td>11398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44083</th>\n",
       "      <td>erUSUL</td>\n",
       "      <td>17653</td>\n",
       "      <td>9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33104</th>\n",
       "      <td>bazhang</td>\n",
       "      <td>17512</td>\n",
       "      <td>6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38388</th>\n",
       "      <td>coz_</td>\n",
       "      <td>14329</td>\n",
       "      <td>5404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13215</th>\n",
       "      <td>Jordan_U</td>\n",
       "      <td>13537</td>\n",
       "      <td>8821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81069</th>\n",
       "      <td>theadmin</td>\n",
       "      <td>13047</td>\n",
       "      <td>6662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51127</th>\n",
       "      <td>iceroot</td>\n",
       "      <td>12884</td>\n",
       "      <td>5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75610</th>\n",
       "      <td>sebsebseb</td>\n",
       "      <td>12826</td>\n",
       "      <td>4758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78031</th>\n",
       "      <td>soreau</td>\n",
       "      <td>12472</td>\n",
       "      <td>7596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>DasEi</td>\n",
       "      <td>11691</td>\n",
       "      <td>6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42148</th>\n",
       "      <td>dr_willis</td>\n",
       "      <td>10642</td>\n",
       "      <td>5902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               users  outgoing  incoming\n",
       "349    ActionParsnip     55125     27053\n",
       "6001       Dr_Willis     36626     16590\n",
       "51341         ikonia     30715     13762\n",
       "43183         edbian     21307      9511\n",
       "54888           jrib     18491     11398\n",
       "44083         erUSUL     17653      9789\n",
       "33104        bazhang     17512      6701\n",
       "38388           coz_     14329      5404\n",
       "13215       Jordan_U     13537      8821\n",
       "81069       theadmin     13047      6662\n",
       "51127        iceroot     12884      5920\n",
       "75610      sebsebseb     12826      4758\n",
       "78031         soreau     12472      7596\n",
       "5126           DasEi     11691      6626\n",
       "42148      dr_willis     10642      5902"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting the agents based on outgoing/incoming messages.\n",
    "incoming_outgoing = pd.merge(from_user_dist, to_user_dist, on='users')\\\n",
    "                    .sort_values(ascending=False, by='outgoing')\n",
    "incoming_outgoing.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic based approach for selecting agents\n",
    "\n",
    "The above quantitative approach does not take into account the topics/knowledge coverage, \n",
    "and the distribution of topics in the conversations. If conversations cover 3 topics in a \n",
    "distribution of 60:20:20, a good approach will be that the top 15 agents should be distributed across \n",
    "the 3 topics in a similar way, i.e., 9:3:3\n",
    "\n",
    "Topics can be seen as clusters, where algorithms like LDA (~soft clustering approach) can be utilized to uncover themes being discussed in the conversations.\n",
    "\n",
    "This approach first identifies n number of topics in the full dataset, and calculate the coverage of each topic in each message, using LDA. LDA identifies topics as a cluster of tokens. N more columns are added to the dataset where each column represents a topic, and holds a % value which is the topic coverage of the message. This final dataset can be queried in a number of ways to make a topic based selection of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequent_n_words(n, word_count_dict):\n",
    "    sorted_word_count = sorted(word_count_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    word_count = sorted_word_count[:n+1]\n",
    "    trace1 = go.Bar(\n",
    "      x = [i[0] for i in word_count], \n",
    "      y = [i[1] for i in word_count], \n",
    "      marker = dict(color='blue'))\n",
    "\n",
    "    data = [trace1]\n",
    "    layout = go.Layout(\n",
    "      title= \"Ngrams Frequency\", \n",
    "      xaxis= dict(\n",
    "      title= \"Ngrams\"), \n",
    "      yaxis=dict(title=\"Count\")\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig, filename='jupyter-styled_bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, num_ngrams):\n",
    "    ngrams = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\", \".join([ngrams[i]\n",
    "                        for i in topic.argsort()[:-num_ngrams - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=10000)\n",
    "data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Improvement: text pre-processing. Removal of stopwords, adjectives, adverbs etc. \n",
    "# which are less likely to represent the topic in a conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "ngrams_cv = count_vectorizer.fit_transform(data_sample['text'])\n",
    "# Ngrams and their count\n",
    "ngrams = count_vectorizer.get_feature_names()\n",
    "counts = ngrams_cv.toarray().sum(axis=0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_frequent_n_words(20, dict(zip(ngrams, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA parameters \n",
    "number_topics = 5\n",
    "topic_ngrams = 20\n",
    "\n",
    "# Learning a topic model on the message texts\n",
    "lda = LDA(n_components=number_topics)\n",
    "lda.fit(ngrams_cv)\n",
    "\n",
    "# Print ngrams in each topic identified by LDA, each topic would have its own weights \n",
    "# over different ngrams.\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, topic_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform text messages into their respective topic distributions\n",
    "message_lda_topics_vectors = lda.transform(ngrams_cv).tolist()\n",
    "\n",
    "# Print topic distribution for 5 sample messages.\n",
    "for n in range(5):    \n",
    "    topic_pr = message_lda_topics_vectors[n]    \n",
    "    print(\"msg: {} topic: {}\\n\".format(n, topic_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.DataFrame(message_lda_topics_vectors, columns = ['Topic 1', 'Topic 2','Topic 3','Topic 4','Topic 5'])\n",
    "topics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column 'message_id' to use it for join with the topic vectors\n",
    "data_sample['message_id'] = range(1, len(data_sample) + 1)\n",
    "data_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning message ids to allow join with the data  \n",
    "topics_df['message_id'] = range(1, len(topics_df) + 1)\n",
    "topics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original dataset extended with topic columns\n",
    "data_sample = pd.merge(data_sample, topics_df, on='message_id')\n",
    "data_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing n agents for a given topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View top texts for a topic\n",
    "data_sample.sort_values(by=['Topic 4'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage of a given topic by different users across all messages\n",
    "topic = 'Topic 1'\n",
    "data_sample_topic = data_sample[['from', topic]].groupby(['from'])\\\n",
    "                    .sum().sort_values(by=[topic], ascending=False)\n",
    "\n",
    "data_sample_topic.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
